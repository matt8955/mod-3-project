{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sec_edgar_downloader in /Users/matt/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: lxml>=4.3.4 in /Users/matt/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from sec_edgar_downloader) (4.3.4)\n",
      "Requirement already satisfied: requests in /Users/matt/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from sec_edgar_downloader) (2.21.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/matt/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from requests->sec_edgar_downloader) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/matt/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from requests->sec_edgar_downloader) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/matt/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from requests->sec_edgar_downloader) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/matt/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages (from requests->sec_edgar_downloader) (2019.3.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install sec_edgar_downloader\n",
    "from sec_edgar_downloader import Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import glob\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/sp500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = df.Symbol.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(sp):\n",
    "    rml = sp.copy()\n",
    "    dl=Downloader('SPLatest')\n",
    "    dl.get_10k_filings(i,2)\n",
    "    rml.remove(i) #fix half listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean(soup):\n",
    "    \n",
    "    '''\n",
    "    Removes tables with >15% numerical characters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    soup : BeautifulSoup object\n",
    "        Parsed result from BeautifulSoup.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    soup : BeautifulSoup object\n",
    "        Parsed result from BeautifulSoup\n",
    "        with numerical tables removed.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Determines percentage of numerical characters\n",
    "    # in a table\n",
    "    def GetDigitPercentage(tablestring):\n",
    "        if len(tablestring)>0.0:\n",
    "            numbers = sum([char.isdigit() for char in tablestring])\n",
    "            length = len(tablestring)\n",
    "            return numbers/length\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    # Evaluates numerical character % for each table\n",
    "    # and removes the table if the percentage is > 15%\n",
    "    [x.extract() for x in soup.find_all('table') if GetDigitPercentage(x.get_text())>0.15]\n",
    "    \n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Replace unicode characters with their\n",
    "    # \"normal\" representations\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    tags = re.compile('<.*?>')\n",
    "    text = re.sub(tags, ' ', text)\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilePaths = [str(name) for name in glob.glob('SPLatest/*/*/*/*.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPLatest/sec_edgar_filings/BLK/10-K/0001564590-19-005479.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = []\n",
    "year2 = []\n",
    "for i in PartialFilePaths:\n",
    "    year.append(i.split('-')[2])\n",
    "for i in year:\n",
    "    if (i[0] == '0') | (i[0] == '1'):\n",
    "        year2.append('20' + i)\n",
    "    else:\n",
    "        year2.append('19' +i)\n",
    "ticker = []\n",
    "for i in PartialFilePaths:\n",
    "    ticker.append(i[12:].split('/')[0])\n",
    "df = pd.DataFrame(year2)\n",
    "df.rename(columns=({0:'Year'}), inplace=True)\n",
    "df['Symbol']=ticker\n",
    "df['FilePath']=PartialFilePaths\n",
    "df.Year = df.Year.apply(lambda x: int(x))\n",
    "df.sort_values(by=['Symbol','Year'], inplace=True)\n",
    "pairs = []\n",
    "for i in range(len(df)-1):\n",
    "    y2 = df.Year.iloc[i+1]\n",
    "    y1 = df.Year.iloc[i]\n",
    "    if (abs(y2 - y1) == 1) & (df.Symbol.iloc[i+1]==df.Symbol.iloc[i]):\n",
    "        pairs.append([df.Year.iloc[i+1], df.Symbol.iloc[i+1],df.FilePath.iloc[i], df.FilePath.iloc[i+1]])\n",
    "def ComputeJaccardSimilarity(words_A, words_B):\n",
    "    \n",
    "    '''\n",
    "    Compute Jaccard similarity between document A and\n",
    "    document B.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words_A : set\n",
    "        Words in document A.\n",
    "    words_B : set\n",
    "        Words in document B\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    jaccard_score : float\n",
    "        Jaccard similarity between document\n",
    "        A and document B.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Count number of words in both A and B\n",
    "    words_intersect = len(words_A.intersection(words_B))\n",
    "    \n",
    "    # Count number of words in A or B\n",
    "    words_union = len(words_A.union(words_B))\n",
    "    \n",
    "    # Compute Jaccard similarity score\n",
    "    jaccard_score = words_intersect / words_union\n",
    "    \n",
    "    return jaccard_score\n",
    "errors = []\n",
    "jaccard_scores = []\n",
    "labels = []\n",
    "for pair in tqdm(jaccard_pairs):    \n",
    "    try:\n",
    "        text1 = str(BeautifulSoup(open(pair[2]), 'html.parser'))\n",
    "        text2 = str(BeautifulSoup(open(pair[3]), 'html.parser'))\n",
    "        words1 = set(text1.split())\n",
    "        words2 = set(text2.split())\n",
    "        jaccard_score = ComputeJaccardSimilarity(words1, words2)\n",
    "        jaccard_scores.append(jaccard_score)\n",
    "    except:\n",
    "        errors.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
